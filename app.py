import streamlit as st
import jieba
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm  # æ–°å¢å­—ä½“ç®¡ç†æ¨¡å—
from gensim import corpora, models
import pandas as pd
import chardet
import os

# é¡µé¢æ ‡é¢˜
st.title("ğŸ“– å°è¯´æ–‡æœ¬åˆ†æç³»ç»Ÿ")

def find_chinese_font():
    """è‡ªåŠ¨æŸ¥æ‰¾ç³»ç»Ÿä¸­å¯ç”¨çš„ä¸­æ–‡å­—ä½“"""
    try:
        # å°è¯•åŠ è½½é¡¹ç›®ç›®å½•ä¸‹çš„å­—ä½“æ–‡ä»¶
        if os.path.exists("SimHei.ttf"):
            return os.path.abspath("SimHei.ttf")
        
        # æŸ¥æ‰¾ç³»ç»Ÿå·²å®‰è£…çš„ä¸­æ–‡å­—ä½“
        font_paths = fm.findSystemFonts()
        chinese_fonts = [
            f for f in font_paths 
            if any(name in f.lower() for name in ['simhei', 'msyh', 'stheitisc', 'songti', 'fangsong'])
        ]
        
        # å¸¸è§ç³»ç»Ÿå­—ä½“è·¯å¾„ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰
        system_fonts = [
            # Windows
            'C:/Windows/Fonts/simhei.ttf',
            'C:/Windows/Fonts/msyh.ttc',
            # MacOS
            '/System/Library/Fonts/Supplemental/Songti.ttc',
            '/System/Library/Fonts/STHeiti Medium.ttc',
            # Linux
            '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'
        ]
        
        # åˆå¹¶æ‰€æœ‰å¯èƒ½çš„å­—ä½“è·¯å¾„
        all_fonts = chinese_fonts + system_fonts
        
        for font in all_fonts:
            if os.path.exists(font):
                return font
        return None
    except Exception as e:
        st.error(f"å­—ä½“æŸ¥æ‰¾å¤±è´¥: {str(e)}")
        return None

def generate_wordcloud(text):
    """ç”Ÿæˆè¯äº‘çš„å¥å£®å®ç°"""
    try:
        # è·å–å­—ä½“è·¯å¾„
        font_path = find_chinese_font()
        
        # é…ç½®è¯äº‘å‚æ•°
        wc = WordCloud(
            font_path=font_path,
            background_color="white",
            width=800,
            height=600,
            collocations=False,  # ç¦ç”¨åŒè¯æ¨¡å¼
            max_words=200,
            margin=2
        )
        
        # ç”Ÿæˆè¯äº‘
        wordcloud = wc.generate(text)
        
        # æ˜¾ç¤ºç»“æœ
        fig, ax = plt.subplots()
        ax.imshow(wordcloud)
        ax.axis("off")
        st.pyplot(fig)
        
        # æ˜¾ç¤ºä½¿ç”¨çš„å­—ä½“ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
        if font_path:
            st.caption(f"ä½¿ç”¨çš„å­—ä½“: {os.path.basename(font_path)}")
        else:
            st.warning("æ­£åœ¨ä½¿ç”¨é»˜è®¤å­—ä½“ï¼Œä¸­æ–‡æ˜¾ç¤ºå¯èƒ½å¼‚å¸¸")

    except Exception as e:
        st.error(f"ç”Ÿæˆè¯äº‘å¤±è´¥: {str(e)}")
        st.markdown("""
            **å¸¸è§è§£å†³æ–¹æ³•ï¼š**
            1. è¯·ç¡®ä¿é¡¹ç›®åŒ…å« [SimHei.ttf](https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf) å­—ä½“æ–‡ä»¶
            2. å¯¹äºæœ¬åœ°è¿è¡Œï¼šå°†å­—ä½“æ–‡ä»¶æ”¾åœ¨ä¸ä»£ç ç›¸åŒçš„ç›®å½•
            3. å¯¹äºäº‘ç«¯éƒ¨ç½²ï¼šç¡®ä¿å­—ä½“æ–‡ä»¶å·²ä¸Šä¼ åˆ°GitHubä»“åº“
        """)

# ...ï¼ˆä¿æŒåŸæœ‰çš„ detect_encoding å’Œ safe_decode å‡½æ•°ä¸å˜ï¼‰...

if uploaded_file:
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆä¿æŒä¸å˜ï¼‰
        raw_data = uploaded_file.read()
        text = safe_decode(raw_data)

        # 1. åˆ†è¯å¤„ç†ï¼ˆä¿æŒä¸å˜ï¼‰
        words = jieba.lcut(text)
        word_freq = pd.Series(words).value_counts().head(20)
        
        # æ˜¾ç¤ºè¯é¢‘è¡¨æ ¼ï¼ˆä¿æŒä¸å˜ï¼‰
        st.subheader("ğŸ“Š é«˜é¢‘è¯æ±‡ç»Ÿè®¡")
        st.dataframe(word_freq)

        # 2. ç”Ÿæˆè¯äº‘ï¼ˆä½¿ç”¨æ–°å‡½æ•°ï¼‰
        st.subheader("â˜ è¯äº‘å›¾")
        generate_wordcloud(" ".join(words))  # ä¿®æ”¹ä¸ºè°ƒç”¨æ–°å‡½æ•°

        # ...ï¼ˆä¿æŒå…¶ä»–éƒ¨åˆ†ä¸å˜ï¼‰...

    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}")
        st.stop()