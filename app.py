import streamlit as st
import jieba
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from gensim import corpora, models
import pandas as pd
import chardet
import os

# ================== åˆå§‹åŒ–å…¨å±€ç»„ä»¶ ==================
st.title("ğŸ“– å°è¯´æ–‡æœ¬åˆ†æç³»ç»Ÿ")
uploaded_file = st.file_uploader("ä¸Šä¼ å°è¯´æ–‡æœ¬æ–‡ä»¶ï¼ˆ.txtï¼‰", type="txt")

# ================== å·¥å…·å‡½æ•°å®šä¹‰ ==================
def find_chinese_font():
    """æ›´å®‰å…¨çš„å­—ä½“æŸ¥æ‰¾å‡½æ•°ï¼ˆå¸¦å››çº§å›é€€æœºåˆ¶ï¼‰"""
    try:
        # 1. ä¼˜å…ˆæ£€æŸ¥é¡¹ç›®ç›®å½•å­—ä½“
        if os.path.exists("SimHei.ttf"):
            return os.path.abspath("SimHei.ttf")
        
        # 2. æŸ¥æ‰¾ç³»ç»Ÿé¢„ç½®è·¯å¾„
        font_paths = [
            # Windows
            'C:\\Windows\\Fonts\\msyh.ttc',
            'C:\\Windows\\Fonts\\simhei.ttf',
            # MacOS
            '/System/Library/Fonts/Supplemental/Songti.ttc',
            # Linux
            '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
            # å¤‡ç”¨è·¯å¾„
            '/usr/share/fonts/truetype/msttcorefonts/SimHei.ttf'
        ]
        
        # 3. éªŒè¯é¢„ç½®è·¯å¾„æœ‰æ•ˆæ€§
        valid_fonts = [f for f in font_paths if os.path.exists(f)]
        if valid_fonts:
            return valid_fonts[0]
        
        # 4. ä½¿ç”¨matplotlibé»˜è®¤ä¸­æ–‡å­—ä½“
        try:
            from matplotlib import rcParams
            default_font = rcParams['font.sans-serif'][0]
            if isinstance(default_font, str):
                return default_font
            return fm.findfont(default_font)
        except:
            return None
            
    except Exception as e:
        st.error(f"å­—ä½“æŸ¥æ‰¾å¤±è´¥: {str(e)}")
        return None

def generate_wordcloud(text):
    """å®Œå…¨é‡å†™çš„è¯äº‘ç”Ÿæˆå‡½æ•°"""
    try:
        # è·å–å­—ä½“è·¯å¾„ï¼ˆå¸¦å®‰å…¨éªŒè¯ï¼‰
        font_path = find_chinese_font()
        
        # éªŒè¯å­—ä½“è·¯å¾„æœ‰æ•ˆæ€§
        if font_path and not os.path.exists(font_path):
            raise FileNotFoundError(f"å­—ä½“æ–‡ä»¶ä¸å­˜åœ¨: {font_path}")
        
        # åˆ›å»ºè¯äº‘å¯¹è±¡
        wc = WordCloud(
            font_path=font_path if font_path else None,
            width=800,
            height=600,
            background_color="white",
            collocations=False,
            max_words=200,
            margin=2,
            prefer_horizontal=0.9  # ä¼˜åŒ–ä¸­æ–‡æ¨ªå‘æ˜¾ç¤º
        )
        
        # ç”Ÿæˆè¯äº‘ï¼ˆå¸¦å¼‚å¸¸æ•è·ï¼‰
        try:
            wordcloud = wc.generate(text)
        except Exception as e:
            raise RuntimeError(f"è¯äº‘ç”Ÿæˆå¤±è´¥: {str(e)}")

        # æ˜¾ç¤ºè¯äº‘
        fig, ax = plt.subplots()
        ax.imshow(wordcloud)
        ax.axis("off")
        
        # æ˜¾å¼å…³é—­ç»˜å›¾ä»¥é‡Šæ”¾å†…å­˜
        st.pyplot(fig, clear_figure=True)
        plt.close('all')
        
        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        st.caption(f"ä½¿ç”¨å­—ä½“è·¯å¾„: {font_path or 'ç³»ç»Ÿé»˜è®¤'}")

    except Exception as e:
        st.error(f"è¯äº‘ç”Ÿæˆå¤±è´¥: {str(e)}")
        st.markdown("""
            **ç´§æ€¥è§£å†³æ–¹æ¡ˆï¼š**
            1. [ä¸‹è½½å¾®è½¯é›…é»‘å­—ä½“](https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf)
            2. å°†æ–‡ä»¶é‡å‘½åä¸º `SimHei.ttf`
            3. ä¸Šä¼ åˆ°é¡¹ç›®æ ¹ç›®å½•
            """)

def safe_decode(raw_data):
    """å®‰å…¨è§£ç å®ç°"""
    try:
        detection = chardet.detect(raw_data)
        encoding = detection['encoding'] or 'utf-8'
        return raw_data.decode(encoding, errors='replace')
    except Exception as e:
        st.error(f"è§£ç å¤±è´¥: {str(e)}")
        return raw_data.decode('utf-8', errors='replace')

# ================== ä¸»å¤„ç†é€»è¾‘ ==================
if uploaded_file is not None:
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        raw_data = uploaded_file.read()
        text = safe_decode(raw_data)

        # 1. åˆ†è¯å¤„ç†
        words = jieba.lcut(text)
        if len(words) == 0:
            raise ValueError("åˆ†è¯ç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹")
            
        # 2. é«˜é¢‘è¯ç»Ÿè®¡
        st.subheader("ğŸ“Š é«˜é¢‘è¯æ±‡ç»Ÿè®¡")
        word_freq = pd.Series(words).value_counts().head(20)
        st.dataframe(word_freq)

        # 3. ç”Ÿæˆè¯äº‘ï¼ˆä½¿ç”¨æ”¹è¿›åçš„å‡½æ•°ï¼‰
        st.subheader("â˜ è¯äº‘å›¾")
        generate_wordcloud(" ".join(words))  # å…³é”®ä¿®æ”¹ç‚¹

        # 4. LDAåˆ†æ
        st.subheader("ğŸ¯ ä¸»é¢˜å…³é”®è¯æå–")
        try:
            dictionary = corpora.Dictionary([words])
            corpus = [dictionary.doc2bow(words)]
            lda = models.LdaModel(corpus, num_topics=3, id2word=dictionary)
            for topic in lda.print_topics():
                st.code(f"ä¸»é¢˜ {topic[0]}: {topic[1]}")
        except Exception as e:
            st.error(f"ä¸»é¢˜åˆ†æå¤±è´¥: {str(e)}")

    except Exception as e:
        st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        st.stop()
else:
    st.info("ğŸ‘† è¯·å…ˆä¸Šä¼ æ–‡æœ¬æ–‡ä»¶")