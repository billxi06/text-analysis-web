import streamlit as st
import jieba
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from gensim import corpora, models
import pandas as pd
import chardet  # ç¡®ä¿å¯¼å…¥chardet

# é¡µé¢æ ‡é¢˜
st.title("ğŸ“– å°è¯´æ–‡æœ¬åˆ†æç³»ç»Ÿ")

def detect_encoding(raw_data):
    """æ›´å¥å£®çš„ç¼–ç æ£€æµ‹å‡½æ•°"""
    try:
        detection = chardet.detect(raw_data)
        encoding = detection['encoding']
        confidence = detection['confidence']
        
        # æ˜¾ç¤ºç¼–ç æ£€æµ‹ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        st.sidebar.write(f"æ£€æµ‹åˆ°ç¼–ç : {encoding} (ç½®ä¿¡åº¦: {confidence:.2%})")
        
        # å¤‡é€‰ç¼–ç ä¼˜å…ˆçº§åˆ—è¡¨ï¼ˆæ ¹æ®ä¸­æ–‡æ–‡æœ¬è°ƒæ•´ï¼‰
        backup_encodings = ['utf-8', 'GB18030', 'GBK', 'GB2312', 'ISO-8859-1']
        
        # ç½®ä¿¡åº¦ä½äº80%æ—¶å°è¯•å¤‡é€‰ç¼–ç 
        if confidence < 0.8:
            for enc in backup_encodings:
                try:
                    _ = raw_data.decode(enc)
                    st.sidebar.write(f"ä½ç½®ä¿¡åº¦ç¼–ç å·²éªŒè¯å¯ç”¨: {enc}")
                    return enc
                except:
                    continue
        
        return encoding if encoding is not None else 'utf-8'
    except Exception as e:
        st.error(f"ç¼–ç æ£€æµ‹å¤±è´¥: {str(e)}")
        return 'utf-8'

def safe_decode(raw_data):
    """å¸¦é”™è¯¯å¤„ç†çš„è§£ç å‡½æ•°"""
    encoding = detect_encoding(raw_data)
    try:
        # ä¼˜å…ˆå°è¯•ä¸¥æ ¼æ¨¡å¼è§£ç 
        return raw_data.decode(encoding)
    except UnicodeDecodeError:
        try:
            # å°è¯•ç”¨å¤‡é€‰ç¼–ç è§£ç 
            return raw_data.decode(encoding, errors='replace')
        except:
            # æœ€ç»ˆå›é€€æ–¹æ¡ˆ
            return raw_data.decode('utf-8', errors='replace')

# ä¸Šä¼ æ–‡ä»¶
uploaded_file = st.file_uploader("ä¸Šä¼ å°è¯´æ–‡æœ¬æ–‡ä»¶ï¼ˆ.txtï¼‰", type="txt")

if uploaded_file:
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        raw_data = uploaded_file.read()
        text = safe_decode(raw_data)  # ä½¿ç”¨æ”¹è¿›çš„è§£ç æ–¹æ³•

        # --- ä»¥ä¸‹ä¸ºåŸæœ‰åˆ†æé€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰ ---
        
        # 1. åˆ†è¯å¤„ç†
        words = jieba.lcut(text)
        word_freq = pd.Series(words).value_counts().head(20)
        
        # æ˜¾ç¤ºè¯é¢‘è¡¨æ ¼
        st.subheader("ğŸ“Š é«˜é¢‘è¯æ±‡ç»Ÿè®¡")
        st.dataframe(word_freq)

        # 2. ç”Ÿæˆè¯äº‘
        st.subheader("â˜ è¯äº‘å›¾")
        wordcloud = WordCloud(
            font_path="SimHei.ttf", 
            background_color="white",
            width=800,  # æ˜ç¡®æŒ‡å®šå°ºå¯¸
            height=600
        ).generate(" ".join(words))
        
        fig, ax = plt.subplots()
        ax.imshow(wordcloud)
        ax.axis("off")
        st.pyplot(fig)

        # 3. LDA ä¸»é¢˜åˆ†æï¼ˆå¢åŠ å¼‚å¸¸æ•è·ï¼‰
        st.subheader("ğŸ¯ ä¸»é¢˜å…³é”®è¯æå–")
        try:
            texts = [words]
            dictionary = corpora.Dictionary(texts)
            corpus = [dictionary.doc2bow(text) for text in texts]
            lda = models.LdaModel(corpus, num_topics=3, id2word=dictionary)
            for topic in lda.print_topics():
                st.write(f"ä¸»é¢˜ {topic[0]}: {topic[1]}")
        except Exception as e:
            st.error(f"ä¸»é¢˜åˆ†æå¤±è´¥: {str(e)}")

        # 4. äººç‰©å…³ç³»åˆ†æï¼ˆç¤ºä¾‹ï¼‰
        st.subheader("ğŸ•¸ äººç‰©å…³ç³»ç½‘ç»œï¼ˆç¤ºä¾‹ï¼‰")
        st.image("https://via.placeholder.com/600x400.png?text=äººç‰©å…³ç³»å›¾", use_column_width=True)

    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}")
        st.stop()