import streamlit as st
import jieba
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from gensim import corpora, models
import pandas as pd
import chardet
import os

# ================== åˆå§‹åŒ–å…¨å±€ç»„ä»¶ ==================
st.title("ğŸ“– å°è¯´æ–‡æœ¬åˆ†æç³»ç»Ÿ")
uploaded_file = st.file_uploader("ä¸Šä¼ å°è¯´æ–‡æœ¬æ–‡ä»¶ï¼ˆ.txtï¼‰", type="txt")  # å¿…é¡»ä½äºå‡½æ•°å®šä¹‰ä¹‹å‰

# ================== å·¥å…·å‡½æ•°å®šä¹‰ ==================
def find_chinese_font():
    """è‡ªåŠ¨æŸ¥æ‰¾ç³»ç»Ÿä¸­å¯ç”¨çš„ä¸­æ–‡å­—ä½“"""
    try:
        # ä¼˜å…ˆæ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•å­—ä½“
        font_candidates = [
            "SimHei.ttf",
            "/usr/share/fonts/truetype/msttcorefonts/SimHei.ttf",
            "C:/Windows/Fonts/simhei.ttf",
            "/System/Library/Fonts/Supplemental/Songti.ttc"
        ]
        
        for font in font_candidates:
            if os.path.exists(font):
                return font
        
        # æŸ¥æ‰¾ç³»ç»Ÿå­—ä½“
        system_fonts = fm.findSystemFonts()
        for font in system_fonts:
            if any(keyword in font.lower() for keyword in ['hei', 'song', 'fang']):
                return font
        return None
    except Exception as e:
        st.error(f"å­—ä½“æŸ¥æ‰¾å¤±è´¥: {str(e)}")
        return None

def safe_decode(raw_data):
    """å®‰å…¨è§£ç å®ç°"""
    try:
        detection = chardet.detect(raw_data)
        encoding = detection['encoding'] or 'utf-8'
        return raw_data.decode(encoding, errors='replace')
    except Exception as e:
        st.error(f"è§£ç å¤±è´¥: {str(e)}")
        return raw_data.decode('utf-8', errors='replace')

# ================== ä¸»å¤„ç†é€»è¾‘ ==================
if uploaded_file is not None:  # æ˜¾å¼åˆ¤æ–­ None æ›´å®‰å…¨
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        raw_data = uploaded_file.read()
        text = safe_decode(raw_data)

        # 1. åˆ†è¯å¤„ç†
        words = jieba.lcut(text)
        if len(words) == 0:
            raise ValueError("åˆ†è¯ç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹")
            
        # 2. é«˜é¢‘è¯ç»Ÿè®¡
        st.subheader("ğŸ“Š é«˜é¢‘è¯æ±‡ç»Ÿè®¡")
        word_freq = pd.Series(words).value_counts().head(20)
        st.dataframe(word_freq)

        # 3. ç”Ÿæˆè¯äº‘
        st.subheader("â˜ è¯äº‘å›¾")
        font_path = find_chinese_font() or fm.findfont(fm.FontProperties(family='sans-serif'))
        
        wc = WordCloud(
            font_path=font_path,
            width=800,
            height=600,
            background_color="white",
            collocations=False
        ).generate(" ".join(words))
        
        fig, ax = plt.subplots()
        ax.imshow(wc)
        ax.axis("off")
        st.pyplot(fig)

        # 4. LDAåˆ†æ
        st.subheader("ğŸ¯ ä¸»é¢˜å…³é”®è¯æå–")
        try:
            dictionary = corpora.Dictionary([words])
            corpus = [dictionary.doc2bow(words)]
            lda = models.LdaModel(corpus, num_topics=3, id2word=dictionary)
            for topic in lda.print_topics():
                st.code(f"ä¸»é¢˜ {topic[0]}: {topic[1]}")
        except Exception as e:
            st.error(f"ä¸»é¢˜åˆ†æå¤±è´¥: {str(e)}")

    except Exception as e:
        st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        st.stop()
else:
    st.info("ğŸ‘† è¯·å…ˆä¸Šä¼ æ–‡æœ¬æ–‡ä»¶")