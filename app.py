import streamlit as st
import jieba
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from gensim import corpora, models
import pandas as pd
import chardet

# é¡µé¢æ ‡é¢˜
st.title("ğŸ“– å°è¯´æ–‡æœ¬åˆ†æç³»ç»Ÿ")

# ä¸Šä¼ æ–‡ä»¶
uploaded_file = st.file_uploader("ä¸Šä¼ å°è¯´æ–‡æœ¬æ–‡ä»¶ï¼ˆ.txtï¼‰", type="txt")

    

if uploaded_file:
     # è¯»å–æ–‡ä»¶å†…å®¹
    raw_data = uploaded_file.read()
    encoding = chardet.detect(raw_data)["encoding"]  # è‡ªåŠ¨æ£€æµ‹ç¼–ç 
    text = raw_data.decode(encoding)                 # ä½¿ç”¨æ£€æµ‹åˆ°çš„ç¼–ç è§£ç 

    # 1. åˆ†è¯å¤„ç†
    words = jieba.lcut(text)
    word_freq = pd.Series(words).value_counts().head(20)
    
    # æ˜¾ç¤ºè¯é¢‘è¡¨æ ¼
    st.subheader("ğŸ“Š é«˜é¢‘è¯æ±‡ç»Ÿè®¡")
    st.dataframe(word_freq)

    # 2. ç”Ÿæˆè¯äº‘
    st.subheader("â˜ï¸ è¯äº‘å›¾")
    wordcloud = WordCloud(font_path="SimHei.ttf", background_color="white").generate(" ".join(words))
    plt.imshow(wordcloud)
    plt.axis("off")
    st.pyplot(plt)

    # 3. LDA ä¸»é¢˜åˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰
    st.subheader("ğŸ¯ ä¸»é¢˜å…³é”®è¯æå–")
    texts = [words]
    dictionary = corpora.Dictionary(texts)
    corpus = [dictionary.doc2bow(text) for text in texts]
    lda = models.LdaModel(corpus, num_topics=3, id2word=dictionary)
    for topic in lda.print_topics():
        st.write(f"ä¸»é¢˜ {topic[0]}: {topic[1]}")

    # 4. äººç‰©å…³ç³»åˆ†æï¼ˆç¤ºä¾‹ï¼‰
    st.subheader("ğŸ•¸ï¸ äººç‰©å…³ç³»ç½‘ç»œï¼ˆç¤ºä¾‹ï¼‰")
    st.image("https://via.placeholder.com/600x400.png?text=äººç‰©å…³ç³»å›¾", use_column_width=True)